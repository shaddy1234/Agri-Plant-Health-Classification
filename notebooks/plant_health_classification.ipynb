{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a207eb",
   "metadata": {},
   "source": [
    "# Problem Definition\n",
    "\n",
    "## Project Title: Agricultural Plant Health Classification\n",
    "\n",
    "### Context\n",
    "Early detection of plant diseases is crucial for maintaining crop health and maximizing yield. Manually inspecting plants is time-consuming and error-prone. This project focuses on developing a classification system to automatically distinguish between healthy and unhealthy plants based on their photographs.\n",
    "\n",
    "### Objective\n",
    "Develop a machine learning model to automatically classify plant images into:\n",
    "- **Healthy Plants**: No disease or stress\n",
    "- **Unhealthy Plants**: Showing signs of disease, pest damage, or stress\n",
    "\n",
    "### Expected Outcome\n",
    "A working proof-of-concept system that predicts the health status of a plant based on images.\n",
    "\n",
    "### Application\n",
    "Farmers and agricultural experts can use this system for timely intervention to prevent crop damage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c9b71-249c-4757-83e9-12541085a72b",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "### Source\n",
    "- Used publicly available dataset from Mendeley Data [Bangladesh Dataset](https://data.mendeley.com/datasets/3wby28tkcp/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d47bc7-a0e6-4037-a575-e4bc9b5cfb08",
   "metadata": {},
   "source": [
    "## Dataset Selection and Preparation\n",
    "\n",
    "### Focus Crop: Bean\n",
    "\n",
    "The dataset used in this project is the **Vegetables Dataset**, which contains images of four different vegetable crops, each divided into healthy and unhealthy categories:\n",
    "```\n",
    "Vegetables Dataset/\n",
    "├── Malabar/\n",
    "│ ├── Healthy/\n",
    "│ └── Unhealthy/\n",
    "├── Brinjal/\n",
    "│ ├── Healthy/\n",
    "│ └── Unhealthy/\n",
    "├── Cauliflower/\n",
    "│ ├── Healthy/\n",
    "│ └── Unhealthy/\n",
    "└── Bean/\n",
    "├── Healthy/\n",
    "└── Unhealthy/\n",
    "```\n",
    "\n",
    "For this **proof-of-concept project**, we focus only on the **Bean** crop, performing a **binary classification**:\n",
    "\n",
    "- **Healthy Beans → label 0**  \n",
    "- **Unhealthy Beans → label 1**\n",
    "\n",
    "### Reasoning\n",
    "\n",
    "Using only a single crop type has several advantages:\n",
    "\n",
    "1. **Reduces variability**: Different crops have different leaf shapes, sizes, and colors. Combining all crops into one model can confuse the classifier and reduce predictive accuracy.\n",
    "2. **Simplifies the baseline model**: By focusing on Bean, the model learns patterns specific to this crop, allowing us to establish a strong baseline before expanding to multiple crops.\n",
    "3. **Demonstrates ML workflow**: The goal is to show end-to-end model building — loading data, preprocessing, feature extraction, training, and evaluation — on a manageable and interpretable subset.\n",
    "\n",
    "### Folder Structure for Bean\n",
    "\n",
    "The **Bean crop images** are organized as follows:\n",
    "```\n",
    "data/\n",
    "└── Bean/\n",
    "├── Healthy/ # Images of healthy bean plants\n",
    "└── Unhealthy/ # Images of diseased or stressed bean plants\n",
    "```\n",
    "\n",
    "Each subfolder corresponds to a **class label**, which will be used during model training.\n",
    "\n",
    " \n",
    "\n",
    "By focusing on this single crop type, the model can learn clear distinguishing patterns between healthy and unhealthy plants, making this a clean **baseline for future expansion** to multi-class or multi-crop classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8b682-751a-4734-8700-0aae3b68ba21",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this section, we prepare the Bean plant images for machine learning. Since we are performing **binary classification** (Healthy vs. Unhealthy), we need to convert the raw images into a format suitable for a **classical ML model** like Logistic Regression.  \n",
    "\n",
    "Steps taken:\n",
    "\n",
    "1. **Image Resizing**  \n",
    "   - All images are resized to a uniform size (64x64 pixels) to ensure consistency across the dataset.  \n",
    "   - Resizing helps reduce computational load while retaining enough detail for the model to learn.\n",
    "\n",
    "2. **Color Conversion and Flattening**  \n",
    "   - Images are converted to RGB to ensure all have 3 color channels.  \n",
    "   - Each image is flattened into a 1-dimensional array of pixel values so that classical ML models can process them.  \n",
    "   - Flattening turns a 64x64x3 image into a 12,288-length feature vector.\n",
    "\n",
    "3. **Label Encoding**  \n",
    "   - Folder names (`Healthy` and `Unhealthy`) are mapped to numeric labels:  \n",
    "     - Healthy - 0  \n",
    "     - Unhealthy - 1  \n",
    "\n",
    "4. **Feature and Label Arrays**  \n",
    "   - All processed images are stored in `X` (features).  \n",
    "   - Corresponding labels are stored in `y` (target).  \n",
    "\n",
    "5. **Verification**  \n",
    "   - We check the shape of `X` and `y` to ensure the data is loaded correctly:  \n",
    "     - `X.shape` - `(number_of_images, 12288)`  \n",
    "     - `y.shape` - `(number_of_images,)`  \n",
    "\n",
    "This preprocessing ensures the images are ready for training a **binary classification model** while keeping the workflow simple and interpretable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121640c0-96b1-4b9d-a38d-725ee857ddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Image Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Healthy: 100%|████████████████████████| 632/632 [01:52<00:00,  5.64it/s]\n",
      "Loading Unhealthy: 100%|████████████████████████| 13/13 [00:02<00:00,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verification ---\n",
      "Features shape (X): (645, 12288)\n",
      "Labels shape (y): (645,)\n",
      "Sample Label (first image): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm # adds a nice loading bar\n",
    "\n",
    "# 1. Define Paths\n",
    "BASE_PATH = '/home/shaddy/Downloads/Dataset on Bangladeshi Healthy and Unhealthy Veget/Vegetables/Bean'\n",
    "CATEGORIES = ['Healthy', 'Unhealthy']\n",
    "IMG_SIZE = 64\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# 2. The Wrangling Loop\n",
    "print(\"Starting Image Processing...\")\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(BASE_PATH, category)\n",
    "    label = CATEGORIES.index(category) # Healthy=0, Unhealthy=1\n",
    "    \n",
    "    for img_name in tqdm(os.listdir(path), desc=f\"Loading {category}\"):\n",
    "        try:\n",
    "            # Read and Convert\n",
    "            img_path = os.path.join(path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Step 1: Resize\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            \n",
    "            # Step 2: Flattening (64*64*3 = 12288)\n",
    "            flattened_img = img.flatten()\n",
    "            \n",
    "            X.append(flattened_img)\n",
    "            y.append(label)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "# Step 4: Convert to Arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Step 6: Normalization\n",
    "X = X / 255.0\n",
    "\n",
    "# Step 5: Verification\n",
    "print(\"\\n--- Verification ---\")\n",
    "print(f\"Features shape (X): {X.shape}\") # Expect (num_images, 12288)\n",
    "print(f\"Labels shape (y): {y.shape}\")     # Expect (num_images,)\n",
    "print(f\"Sample Label (first image): {y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18615a9-1589-4c91-b5b8-c893de26624f",
   "metadata": {},
   "source": [
    "**Note on Class Imbalance**\n",
    "\n",
    "After loading the images, we notice that the dataset is highly imbalanced:\n",
    "\n",
    "- Healthy: 632 images\n",
    "- Unhealthy: 13 images\n",
    "\n",
    "This imbalance can affect model performance, especially for minority classes.  \n",
    "In a production scenario, techniques like **class weighting, oversampling the minority class and others** could help mitigate this issue.  \n",
    "\n",
    "For this proof-of-concept, we proceed with the dataset as-is, but the imbalance is noted for consideration during evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bba458-a2c2-4264-bbba-d08a66314bcf",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "We train a Logistic Regression model to classify Bean plant images as Healthy (0) or Unhealthy (1).\n",
    "\n",
    "- The training and test sets are split with an 80/20 ratio, preserving class distribution (`stratify=y`).\n",
    "- Logistic Regression is used with `class_weight='balanced'` to partially account for the imbalanced dataset.\n",
    "- Evaluation to be  done using Accuracy, Confusion Matrix, and classification metrics (Precision, Recall, F1-score) to understand model performance on both classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b89128-ec5f-40b6-b3ee-7f6bf5785706",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "We split our data into training and testing sets so you can evaluate performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a4af28f-a43b-4f0b-83f2-95e31927b2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (516, 12288) (516,)\n",
      "Test set: (129, 12288) (129,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b2298-4f64-4cf4-8420-b7e4c75fb762",
   "metadata": {},
   "source": [
    "### Logistic Regression Implementation\n",
    "- I implemented LR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e904ed61-458b-4aac-be0f-fcacef642d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9457364341085271\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       126\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       129\n",
      "   macro avg       0.49      0.48      0.49       129\n",
      "weighted avg       0.95      0.95      0.95       129\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[122   4]\n",
      " [  3   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced')  # 'balanced' helps with class imbalance\n",
    "\n",
    "# Train\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee4d24-8392-4a96-89ec-feb17507a205",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "The Logistic Regression model achieved 94.5% accuracy. However, due to the severe class imbalance (126 Healthy vs 3 Unhealthy in the test set), the model fails to correctly classify any Unhealthy plants. \n",
    "\n",
    "- All Unhealthy plants in the test set were misclassified as Healthy.\n",
    "- This highlights the importance of handling class imbalance, e.g., through oversampling, class weighting, or collecting more Unhealthy images.\n",
    "- While overall accuracy is high, the Recall for the 'Unhealthy' class is 0%. In an agricultural context, this is a 'False Negative' and is the most costly error. This proves that the model is simply 'learning' the distribution of the data (predicting the majority class) rather than learning the features of the disease.\"\n",
    "\n",
    "For this proof-of-concept, I document the results and noted that the model performs well for the majority class but poorly for the minority class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69c590b-0f74-4ed8-bafa-8e2e0a48a95d",
   "metadata": {},
   "source": [
    "# Trying Other Classifiers\n",
    "\n",
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37da257-966f-40f6-baa3-57ec754f55a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9767441860465116\n",
      "\n",
      "Classification Report (SVM):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       126\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.98       129\n",
      "   macro avg       0.49      0.50      0.49       129\n",
      "weighted avg       0.95      0.98      0.97       129\n",
      "\n",
      "Confusion Matrix (SVM):\n",
      " [[126   0]\n",
      " [  3   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaddy/envs/data_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/shaddy/envs/data_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/shaddy/envs/data_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize SVM\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',          # Non-linear decision boundary\n",
    "    class_weight='balanced',  # Handle class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report (SVM):\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"Confusion Matrix (SVM):\\n\", confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142504a8-9536-4dd1-897f-cf7cb0db8b1c",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a749df92-69cc-4d98-a378-c3a9992961b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9767441860465116\n",
      "\n",
      "Classification Report (RF):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       126\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.98       129\n",
      "   macro avg       0.49      0.50      0.49       129\n",
      "weighted avg       0.95      0.98      0.97       129\n",
      "\n",
      "Confusion Matrix (RF):\n",
      " [[126   0]\n",
      " [  3   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaddy/envs/data_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/shaddy/envs/data_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/shaddy/envs/data_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report (RF):\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix (RF):\\n\", confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736119-b572-461b-9fbc-709484700e5a",
   "metadata": {},
   "source": [
    "## Model Comparisons\n",
    "\n",
    "In evaluated different multiple classification models to assess their performance on the plant health dataset. Due to class imbalance, accuracy alone is not sufficient, so precision, recall, F1-score, and confusion matrices are also considered.\n",
    "\n",
    "#### Logistic Regression\n",
    "\n",
    "**Accuracy:** 94.6%\n",
    "\n",
    "The Logistic Regression model serves as the baseline classifier.\n",
    "\n",
    "**Observations from Confusion Matrix:**\n",
    "- Performs well on the majority class (Healthy)\n",
    "- Fails to correctly classify any samples from the minority class (Unhealthy)\n",
    "- High accuracy is misleading due to severe class imbalance\n",
    "\n",
    "#### Support Vector Machine (SVM)\n",
    "\n",
    "**Accuracy:** 97.7%\n",
    "\n",
    "**Observations from confusion matrix:**\n",
    "- Correctly classifies all healthy samples\n",
    "- Does not detect any unhealthy samples\n",
    "- Demonstrates stronger bias toward the majority class\n",
    "\n",
    "#### Random Forest Classifier\n",
    "\n",
    "**Accuracy:** 97.7%\n",
    "\n",
    "**Observations from Confusion matrix:**\n",
    "- Ensemble method improves stability\n",
    "- Still fails to identify the minority class\n",
    "- Accuracy increase does not translate to better class balance\n",
    "\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "Although all models achieve high accuracy, none successfully classify the minority (unhealthy) class. This highlights the limitations of traditional machine learning models when applied to highly imbalanced image datasets.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- Accuracy alone is not a reliable metric for imbalanced classification problems\n",
    "- Traditional classifiers struggle with raw image features\n",
    "- More advanced approaches such as class weighting, data augmentation, or Convolutional Neural Networks (CNNs) are likely required for better performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f62a8-ce4d-405f-9bae-822be64f98f9",
   "metadata": {},
   "source": [
    "### Trying a simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bebb54f4-f6ac-4ed7-a1f6-a93b8c9521b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 07:52:21.747650: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-28 07:52:21.999526: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-28 07:52:27.785003: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/home/shaddy/envs/data_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2026-01-28 07:52:30.510844: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 216ms/step - accuracy: 0.7364 - loss: 1.6412\n",
      "Epoch 2/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 218ms/step - accuracy: 0.9806 - loss: 1.3875\n",
      "Epoch 3/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 231ms/step - accuracy: 0.9806 - loss: 1.4007\n",
      "Epoch 4/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 196ms/step - accuracy: 0.5097 - loss: 1.3513\n",
      "Epoch 5/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.5659 - loss: 1.3505\n",
      "Epoch 6/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 211ms/step - accuracy: 0.9787 - loss: 1.3544\n",
      "Epoch 7/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.9535 - loss: 1.3368\n",
      "Epoch 8/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.9089 - loss: 1.2207\n",
      "Epoch 9/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 234ms/step - accuracy: 0.6977 - loss: 1.3293\n",
      "Epoch 10/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 230ms/step - accuracy: 0.7287 - loss: 1.2949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7987d83e7f20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 1. Reshape data back to images (since CNNs need 3D shapes, not flat lines)\n",
    "X_train_cnn = X_train.reshape(-1, 64, 64, 3)\n",
    "X_test_cnn = X_test.reshape(-1, 64, 64, 3)\n",
    "\n",
    "# 2. Build a Simple CNN\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid') # Binary output\n",
    "])\n",
    "\n",
    "# 3. Compile and Train\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Use class_weight to help with the imbalance\n",
    "cnn_model.fit(X_train_cnn, y_train, epochs=10, class_weight={0: 1, 1: 50})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b7785-1a65-4b58-b9a4-5e8041ebbb81",
   "metadata": {},
   "source": [
    "## Conclusion, Reflection, and Challenges\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This project demonstrates an end-to-end workflow for binary image classification of Bean plant health, progressing from classical machine learning baselines to an exploratory deep learning approach.\n",
    "\n",
    "The objective was to classify images as **Healthy (0)** or **Unhealthy (1)** to support early detection of plant stress or disease.\n",
    "\n",
    "\n",
    "### Dataset and Preprocessing Summary\n",
    "\n",
    "- Images were loaded from a folder-based structure (`Healthy`, `Unhealthy`) using OpenCV.\n",
    "- All images were:\n",
    "  - Converted to RGB\n",
    "  - Resized to **64×64**\n",
    "  - Normalized to the range **[0, 1]**\n",
    "- For classical machine learning models, images were **flattened into 1D feature vectors**.\n",
    "- Final dataset shape:\n",
    "  - `X.shape = (645, 12288)`\n",
    "  - `y.shape = (645,)`\n",
    "- A **severe class imbalance** was observed:\n",
    "  - Healthy: 632 samples\n",
    "  - Unhealthy: 13 samples\n",
    "\n",
    "This imbalance strongly influenced model behavior and evaluation.\n",
    "\n",
    "\n",
    "### Modeling Approach\n",
    "\n",
    "To align with my current learning stage and ensure clarity, I followed a **progressive modeling strategy**:\n",
    "\n",
    "#### Classical Machine Learning (Baseline)\n",
    "- **Logistic Regression**\n",
    "- **Support Vector Machine (SVM)**\n",
    "- **Random Forest Classifier**\n",
    "\n",
    "These models were chosen to:\n",
    "- Establish interpretable baselines\n",
    "- Apply concepts learned from regression (data splitting, scaling, evaluation)\n",
    "- Highlight limitations when applied to image data\n",
    "\n",
    "#### Deep Learning (Exploratory)\n",
    "- Implemented a **simple Convolutional Neural Network (CNN)** to assess the suitability of deep learning for this task.\n",
    "- I used CNN as a proof-of-concept, not a final production model.\n",
    "\n",
    "\n",
    "### Model Evaluation and Insights\n",
    "\n",
    "#### Classical Models\n",
    "- All classical models achieved **high overall accuracy (94–98%)**.\n",
    "- However, **none successfully detected the Unhealthy class**.\n",
    "- Confusion matrices and classification reports showed:\n",
    "  - Perfect or near-perfect performance on the majority class\n",
    "  - Zero recall for the minority class\n",
    "\n",
    "This reinforces an important lesson:\n",
    " **Accuracy alone is misleading for imbalanced classification problems.**\n",
    "\n",
    "#### CNN Experiment\n",
    "- The CNN demonstrated the ability to learn spatial features directly from images.\n",
    "- Training accuracy fluctuated significantly across epochs.\n",
    "- Loss remained unstable due to:\n",
    "  - Small dataset size\n",
    "  - Extreme class imbalance\n",
    "  - Lack of validation split and regularization\n",
    "\n",
    "The CNN results highlight both the potential and sensitivity of deep learning models when applied to limited data.\n",
    "\n",
    "\n",
    "### Reflection and Learning Outcomes\n",
    "\n",
    "This project strengthened my understanding of:\n",
    "\n",
    "- How classification workflows closely mirror regression workflows:\n",
    "  - Data preprocessing\n",
    "  - Train/test splitting\n",
    "  - Model selection\n",
    "  - Evaluation and interpretation\n",
    "- The importance of choosing metrics beyond accuracy\n",
    "- The practical limitations of classical ML on image data\n",
    "- Why CNNs are the preferred approach for computer vision tasks, even though they require:\n",
    "  - More data\n",
    "  - Careful tuning\n",
    "  - Regularization strategies\n",
    "\n",
    "\n",
    "### Challenges Encountered\n",
    "\n",
    "#### 1. Data Availability and Imbalance\n",
    "- Locating and isolating Bean images from a larger dataset required manual inspection.\n",
    "- The extreme imbalance (13 unhealthy samples) limited meaningful learning for minority classes.\n",
    "\n",
    "#### 2. Transition from Regression to Classification\n",
    "- My prior experience was primarily regression-focused.\n",
    "- I had to quickly learn:\n",
    "  - Binary classification concepts\n",
    "  - Precision, recall, F1-score\n",
    "  - Confusion matrix interpretation\n",
    "\n",
    "#### 3. Image-to-Feature Conversion\n",
    "- Classical models required images to be flattened, which:\n",
    "  - Loses spatial information\n",
    "  - Motivated exploration of CNNs\n",
    "\n",
    "Due to time constraints and my current learning stage, this project intentionally focuses on:\n",
    "- Building a strong classical ML baseline\n",
    "- Demonstrating awareness of limitations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
